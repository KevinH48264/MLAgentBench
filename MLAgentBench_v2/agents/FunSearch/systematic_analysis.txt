Part / Option to try using to better achieve the research goal

0. Data pre-processing / cleaning. Expected value: Low, I already have data pre-processing pretty well handled.
0.1: Experimenting with more complex imputation methods for handling missing data. Expected value: Low, because I already have data pre-processing pretty well handled.
0.2: Non-linear scaling methods such as RobustScaler or MinMaxScaler for numerical variables. Expected value: I'm not really sure if this is necessary, please tell me if it is.
1. Feature Engineering. Expected value: Valid
1.1 Incorporate more domain knowledge. Expected value: Likely it'll be to hard to incorporate more domain knowledge?
1.2 Priciple Component Analysis. Expected value: I don't think PCA makes sense for feature engineering really.
1.3 Automate the iteration of experiments. Expected value: I think this is unnecessary.
1.4 Assessing the addition of interaction terms or polynomial features for numerical columns. Expected value: Unsure
1.5 Employing feature engineering techniques to extract more information from the data (e.g., interaction between features, more complex transformations). Expected value: Unsure, although we probably don't need to go that crazy.
2. Model Selection. Expected value: Valid
2.1 Advanced ensemble techniques. Expected value: I don't think it needs to be that complex for housing prices / we'll see much gains.
2.2 Stacking more diverse models. Expected value: I don't think it needs to be that complex for housing prices / we'll see much gains.
3. Model Training. Expected value: Valid
3.1 Model hyperparameter tuning should remain iterative guided by cross-validation results. Expected value: I agree, model hyperparameter tuning would help.
3.2 Expanding the hyperparameter search space, specifically adding 'gamma' and 'reg_alpha' to control regularization. Expected value: I really don't think this is necessary to make it this complex.
3.3 Trying out other machine learning models such as GradientBoostingRegressor or RandomForestRegressor and comparing their performance. Expected value: Sure, this quick test could probably work and then I can update this expected value.
4. Evaluation. Expected value: Valid
4.1 Checking for overfitting. Expected value: this is probably an easy change by just adding some print statements to the existing code for training value. There is likely overfitting happening.
4.2 Conducting a detailed error analysis to understand where the model is making the largest mistakes and adjusting accordingly. Expected value: I mean sure, but to maintain the code value otherwise this won't get saved, you'd just have to do some print statements on top of the existing code.