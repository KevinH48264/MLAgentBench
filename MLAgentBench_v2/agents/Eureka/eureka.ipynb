{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the key factors of Eureka is that it tries 32 different approaches before taking the best one and its history. This is very similar to a MCTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode:\n",
    "# 1 system prompt to just write a train.py file\n",
    "# 2 run this 32 times\n",
    "# 3 execute all 32\n",
    "# 4 take the best one and save its training history\n",
    "\n",
    "# Prompt 2: Reward reflection and feedback\n",
    "# 5 reward reflection and feedback\n",
    "# 6 run this 32 times\n",
    "# 7 execute all 32\n",
    "# 8 take the best one and save its training history\n",
    "# 9 repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory:  c:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\MLAgentBench\\MLAgentBench_v2\\agents\\Eureka\\..\\..\\..\n",
      "New Working Directory: c:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\MLAgentBench\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the new working directory relative to the current working directory\n",
    "# or use an absolute path\n",
    "new_working_directory = os.path.join(os.getcwd(), '..', '..', '..') # Set to MLAgentBenhc\n",
    "print(\"New working directory: \", new_working_directory)\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_working_directory)\n",
    "\n",
    "print(\"New Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLAgentBench_v2.agents.agent import Agent\n",
    "import numpy as np \n",
    "import json\n",
    "import logging \n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time \n",
    "import types\n",
    "import copy\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'helm'\n",
      "Could not load CRFM API key crfm_api_key.txt.\n",
      "[Errno 2] No such file or directory: 'claude_api_key.txt'\n",
      "Could not load anthropic API key claude_api_key.txt.\n",
      "Initializing environment...\n",
      "args namespace(task='home-data-for-ml-course', task_type='kaggle', log_dir='logs/house-price-testing_eureka_gpt4_v3', work_dir='workspace', max_steps=50, max_time=18000, device=0, python='/home/user/micromamba/envs/autogpt/bin/python', interactive=False, resume=None, resume_step=0, agent_type='VoyagerAgent', llm_name='gpt-4-1106-preview', fast_llm_name='gpt-4-1106-preview', edit_script_llm_name='gpt-4-1106-preview', edit_script_llm_max_tokens=4000, agent_max_steps=50, actions_remove_from_prompt=[], actions_add_to_prompt=[], no_retrieval=False, valid_format_entires=None, max_steps_in_context=3, max_observation_steps_in_context=3, max_retries=4, langchain_agent='zero-shot-react-description')\n",
      "Preparing task home-data-for-ml-course , of type:  kaggle\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an environment\n",
    "from types import SimpleNamespace\n",
    "from MLAgentBench_v2.environment import Environment\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    task='home-data-for-ml-course',\n",
    "    task_type='kaggle',\n",
    "    log_dir='logs/house-price-testing_eureka_gpt4_v3',\n",
    "    work_dir='workspace',\n",
    "    max_steps=50,\n",
    "    max_time=18000,\n",
    "    device=0,\n",
    "    python='/home/user/micromamba/envs/autogpt/bin/python',\n",
    "    interactive=False,\n",
    "    resume=None,\n",
    "    resume_step=0,\n",
    "    agent_type='VoyagerAgent', # Just for instantiation -- doesn't actually do anything\n",
    "    # llm_name='gpt-3.5-turbo-1106',\n",
    "    # fast_llm_name='gpt-3.5-turbo-1106',\n",
    "    # edit_script_llm_name='gpt-3.5-turbo-1106',\n",
    "    llm_name='gpt-4-1106-preview',\n",
    "    fast_llm_name='gpt-4-1106-preview',\n",
    "    edit_script_llm_name='gpt-4-1106-preview',\n",
    "    edit_script_llm_max_tokens=4000,\n",
    "    agent_max_steps=50,\n",
    "    actions_remove_from_prompt=[],\n",
    "    actions_add_to_prompt=[],\n",
    "    no_retrieval=False,\n",
    "    valid_format_entires=None,\n",
    "    max_steps_in_context=3,\n",
    "    max_observation_steps_in_context=3,\n",
    "    max_retries=4,\n",
    "    langchain_agent='zero-shot-react-description'\n",
    ")\n",
    "\n",
    "env = Environment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path you want to create\n",
    "directory_path = env.work_dir + '/eureka'\n",
    "\n",
    "# Check if the directory already exists to avoid errors\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode:\n",
    "# 1 system prompt to just write a train.py file\n",
    "\n",
    "class EurekaAgent(Agent):\n",
    "    def __init__(self, env, completed_tasks=[], failed_tasks=[]):\n",
    "        super().__init__(env)\n",
    "        self.completed_tasks = env.completed_tasks\n",
    "        self.failed_tasks = env.failed_tasks\n",
    "\n",
    "    def initial_system_prompt(self, env):\n",
    "        self.system_prompt_initial = f'''You are a machine learning engineer trying to write machine learning pipelines to solve machine learning tasks as effectively as possible.\n",
    "\n",
    "Your goal is to write a model training script for the environment that will help the model achieve the highest accuracy possible.\n",
    "\n",
    "Research Goal: {self.research_problem}\n",
    "\n",
    "I will give you the following information:\n",
    "Files: these are my current files and its contents that I have in my working directory.\n",
    "\n",
    "The output format should be executable python code, and only code.\n",
    "'''\n",
    "        self.user_prompt_initial = \"\"\n",
    "        for file in self.files:\n",
    "            args = {\n",
    "                'file_name': file, \n",
    "                'update_files_action_result_history': False\n",
    "            }\n",
    "            self.user_prompt_initial += f'''\\nFilename: {file}. Content: {self.available_actions['readFile'](**args)}\\n'''\n",
    "        print(\"\\nSystem prompt: \\n\" + self.system_prompt_initial)\n",
    "        print(\"\\nUser prompt: \\n\" + self.user_prompt_initial)\n",
    "\n",
    "        complete_text_args = {\n",
    "            'system_prompt': self.system_prompt_initial,\n",
    "            'user_prompt': self.user_prompt_initial,\n",
    "            'max_tokens': 4096,\n",
    "            'temperature': 1.0,\n",
    "            'top_p': 1.0,\n",
    "            'update_files_action_result_history': False,\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        for i in range(2):\n",
    "            output = env.complete_text_openai(**complete_text_args) # increase randomness as much as possible\n",
    "            print(\"\\nOutput: \\n\" + output)\n",
    "            \n",
    "            # TODO: potentially use the assistants API to take the output and ensure that it's in proper pythom format\n",
    "            write_as_python_code_args = {\n",
    "                'system_prompt': 'You are a helpful assistant. Please take the following code and return the content you would write into a python script file. Do not include the ```python or ``` at the beginning and end of the code.',\n",
    "                'user_prompt': output,\n",
    "                'max_tokens': 4096,\n",
    "                'temperature': 0.0,\n",
    "                'top_p': 0.0,\n",
    "                'update_files_action_result_history': False,\n",
    "            }\n",
    "            output = env.complete_text_openai(**write_as_python_code_args)\n",
    "            \n",
    "            # Write to file\n",
    "            write_args = {\n",
    "                'file_name': f'eureka/run_1_script_{i}.py',\n",
    "                'content': output,\n",
    "                'update_files_action_result_history': False,\n",
    "            }\n",
    "            env.write_file(**write_args)\n",
    "\n",
    "            # Execute file\n",
    "            execute_args = {\n",
    "                'script_name': f'eureka/run_1_script_{i}.py',\n",
    "                'update_files_action_result_history': False,\n",
    "            }\n",
    "            result = env.execute_script(**execute_args)\n",
    "            results.append(result)\n",
    "\n",
    "        print(\"Results: \", results)\n",
    "        return results            \n",
    "\n",
    "eureka_agent = EurekaAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- LOGGING NEW ACTION ---\n",
      "Step: 23\n",
      "Calling function wrapped_read_file(args = (), kwargs = {'file_name': ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz'], 'work_dir': 'workspace\\\\home-data-for-ml-course_branch'})\n",
      "\n",
      "--- TOOL ERROR --- cannot read file ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']: join() argument must be str, bytes, or os.PathLike object, not 'list'\n",
      "\n",
      "\n",
      "--- Step: 24 not recorded in history\n",
      "\n",
      "--- Step Action: Calling function wrapped_read_file(args = (), kwargs = {'file_name': ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz'], 'work_dir': '.'})\n",
      "\n",
      "--- Step Result: EnvError: cannot read file ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']: join() argument must be str, bytes, or os.PathLike object, not 'list'\n",
      "\n",
      "\n",
      "System prompt: \n",
      "You are a machine learning engineer trying to write machine learning pipelines to solve machine learning tasks as effectively as possible.\n",
      "\n",
      "Your goal is to write a model training script for the environment that will help the model achieve the highest accuracy possible.\n",
      "\n",
      "Research Goal: Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
      "\n",
      "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
      "\n",
      "Evaluation\n",
      "Goal\n",
      "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. You want a train and validation MAE of lower than 15,000 and there should be a submission.csv containing predictions for test.csv ready to submit.\n",
      "\n",
      "Metric\n",
      "Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n",
      "\n",
      "Submission File Format\n",
      "The file should contain a header and have the following format:\n",
      "\n",
      "Id,SalePrice\n",
      "1461,169000.1\n",
      "1462,187724.1233\n",
      "1463,175221\n",
      "etc.\n",
      "\n",
      "I will give you the following information:\n",
      "Files: these are my current files and its contents that I have in my working directory.\n",
      "\n",
      "The output format should be executable python code, and only code.\n",
      "\n",
      "\n",
      "User prompt: \n",
      "\n",
      "Filename: ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']. Content: EnvError: cannot read file ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']: join() argument must be str, bytes, or os.PathLike object, not 'list'\n",
      "\n",
      "\n",
      "\n",
      "--- LOGGING NEW ACTION ---\n",
      "Step: 24\n",
      "Calling function wrapped_complete_text_openai(args = (), kwargs = {'system_prompt': \"You are a machine learning engineer trying to write machine learning pipelines to solve machine learning tasks as effectively as possible.\\n\\nYour goal is to write a model training script for the environment that will help the model achieve the highest accuracy possible.\\n\\nResearch Goal: Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\\n\\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\\n\\nEvaluation\\nGoal\\nIt is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. You want a train and validation MAE of lower than 15,000 and there should be a submission.csv containing predictions for test.csv ready to submit.\\n\\nMetric\\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\\n\\nSubmission File Format\\nThe file should contain a header and have the following format:\\n\\nId,SalePrice\\n1461,169000.1\\n1462,187724.1233\\n1463,175221\\netc.\\n\\nI will give you the following information:\\nFiles: these are my current files and its contents that I have in my working directory.\\n\\nThe output format should be executable python code, and only code.\\n\", 'user_prompt': \"\\nFilename: ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']. Content: EnvError: cannot read file ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']: join() argument must be str, bytes, or os.PathLike object, not 'list'\\n\", 'max_tokens': 4096, 'temperature': 1.0, 'top_p': 1.0, 'work_dir': 'workspace\\\\home-data-for-ml-course_branch'})\n",
      "\n",
      "--- TOOL SUCCESS ---\n",
      "\n",
      "\n",
      "--- Step: 25 not recorded in history\n",
      "\n",
      "--- Step Action: Calling function wrapped_complete_text_openai(args = (), kwargs = {'system_prompt': \"You are a machine learning engineer trying to write machine learning pipelines to solve machine learning tasks as effectively as possible.\\n\\nYour goal is to write a model training script for the environment that will help the model achieve the highest accuracy possible.\\n\\nResearch Goal: Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\\n\\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\\n\\nEvaluation\\nGoal\\nIt is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. You want a train and validation MAE of lower than 15,000 and there should be a submission.csv containing predictions for test.csv ready to submit.\\n\\nMetric\\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\\n\\nSubmission File Format\\nThe file should contain a header and have the following format:\\n\\nId,SalePrice\\n1461,169000.1\\n1462,187724.1233\\n1463,175221\\netc.\\n\\nI will give you the following information:\\nFiles: these are my current files and its contents that I have in my working directory.\\n\\nThe output format should be executable python code, and only code.\\n\", 'user_prompt': \"\\nFilename: ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']. Content: EnvError: cannot read file ['data_description.txt', 'eureka', 'research_problem.txt', 'sample_submission.csv', 'sample_submission.csv.gz', 'test.csv', 'test.csv.gz', 'train.csv', 'train.csv.gz']: join() argument must be str, bytes, or os.PathLike object, not 'list'\\n\", 'max_tokens': 4096, 'temperature': 1.0, 'top_p': 1.0, 'work_dir': '.'})\n",
      "\n",
      "--- Step Result: It seems there was an attempt to read multiple files at once which caused an error. To solve the machine learning task, we want to write a Python script that reads the training data, preprocesses it, creates a model, performs training, validation, and finally, predicts sale prices for the houses in the test set. Here's a sample code to get you started:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "# Load training data\n",
      "train_data = pd.read_csv('train.csv')\n",
      "\n",
      "# Preprocessing\n",
      "# Define features and target\n",
      "X = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
      "y = train_data['SalePrice']\n",
      "X = pd.get_dummies(X, dummy_na=True)  # Convert categorical data to one-hot encoding\n",
      "\n",
      "# Split training data into training and validation subsets\n",
      "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
      "\n",
      "# Define and configure the model\n",
      "model = make_pipeline(\n",
      "    SimpleImputer(strategy='median'),  # Impute missing values\n",
      "    StandardScaler(),  # Scale features\n",
      "    RandomForestRegressor(n_estimators=100, random_state=0)  # Random Forest model\n",
      ")\n",
      "\n",
      "# Train the model\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Predict on validation set\n",
      "y_pred = model.predict(X_valid)\n",
      "\n",
      "# Evaluate the model\n",
      "mae = mean_absolute_error(y_valid, y_pred)\n",
      "\n",
      "if mae < 15000:\n",
      "    print(f\"Validation MAE: {mae:.2f}\")\n",
      "\n",
      "    # If validation MAE is below 15,000, proceed to predict on test set\n",
      "    test_data = pd.read_csv('test.csv')\n",
      "    test_X = test_data.drop(['Id'], axis=1)\n",
      "    test_X = pd.get_dummies(test_X, dummy_na=True)\n",
      "    test_X = test_X.reindex(columns=X.columns, fill_value=0)  # Ensure the test data has the same columns as the training set\n",
      "\n",
      "    # Predict sale prices on test data\n",
      "    test_preds = model.predict(test_X)\n",
      "\n",
      "    # Save the predictions to a CSV file\n",
      "    output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_preds})\n",
      "    output.to_csv('submission.csv', index=False)\n",
      "    print(\"Submission CSV is ready.\")\n",
      "else:\n",
      "    print(f\"Validation MAE of {mae:.2f} did not meet the required threshold.\")\n",
      "```\n",
      "\n",
      "This script:\n",
      "1. Loads the training data.\n",
      "2. Preprocesses it, dealing with categorical variables through one-hot encoding.\n",
      "3. Splits it into training and validation sets.\n",
      "4. Defines a model pipeline that handles missing values, scales features, and trains a Random Forest.\n",
      "5. Trains the model on the training set.\n",
      "6. Evaluates the model using MAE on the validation set.\n",
      "7. If the validation MAE is lower than $15,000, it predicts on the test set.\n",
      "8. Creates a submission file consistent with the competition's format.\n",
      "\n",
      "Please note that this is a starting point; the preprocessing and model selection might need to be refined to achieve the MAE goal you've described. Hyperparameter tuning, feature engineering, and possibly the use of more sophisticated models can further improve the MAE.\n",
      "\n",
      "\n",
      "Output: \n",
      "It seems there was an attempt to read multiple files at once which caused an error. To solve the machine learning task, we want to write a Python script that reads the training data, preprocesses it, creates a model, performs training, validation, and finally, predicts sale prices for the houses in the test set. Here's a sample code to get you started:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "# Load training data\n",
      "train_data = pd.read_csv('train.csv')\n",
      "\n",
      "# Preprocessing\n",
      "# Define features and target\n",
      "X = train_data.drop(['SalePrice', 'Id'], axis=1)\n",
      "y = train_data['SalePrice']\n",
      "X = pd.get_dummies(X, dummy_na=True)  # Convert categorical data to one-hot encoding\n",
      "\n",
      "# Split training data into training and validation subsets\n",
      "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
      "\n",
      "# Define and configure the model\n",
      "model = make_pipeline(\n",
      "    SimpleImputer(strategy='median'),  # Impute missing values\n",
      "    StandardScaler(),  # Scale features\n",
      "    RandomForestRegressor(n_estimators=100, random_state=0)  # Random Forest model\n",
      ")\n",
      "\n",
      "# Train the model\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Predict on validation set\n",
      "y_pred = model.predict(X_valid)\n",
      "\n",
      "# Evaluate the model\n",
      "mae = mean_absolute_error(y_valid, y_pred)\n",
      "\n",
      "if mae < 15000:\n",
      "    print(f\"Validation MAE: {mae:.2f}\")\n",
      "\n",
      "    # If validation MAE is below 15,000, proceed to predict on test set\n",
      "    test_data = pd.read_csv('test.csv')\n",
      "    test_X = test_data.drop(['Id'], axis=1)\n",
      "    test_X = pd.get_dummies(test_X, dummy_na=True)\n",
      "    test_X = test_X.reindex(columns=X.columns, fill_value=0)  # Ensure the test data has the same columns as the training set\n",
      "\n",
      "    # Predict sale prices on test data\n",
      "    test_preds = model.predict(test_X)\n",
      "\n",
      "    # Save the predictions to a CSV file\n",
      "    output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_preds})\n",
      "    output.to_csv('submission.csv', index=False)\n",
      "    print(\"Submission CSV is ready.\")\n",
      "else:\n",
      "    print(f\"Validation MAE of {mae:.2f} did not meet the required threshold.\")\n",
      "```\n",
      "\n",
      "This script:\n",
      "1. Loads the training data.\n",
      "2. Preprocesses it, dealing with categorical variables through one-hot encoding.\n",
      "3. Splits it into training and validation sets.\n",
      "4. Defines a model pipeline that handles missing values, scales features, and trains a Random Forest.\n",
      "5. Trains the model on the training set.\n",
      "6. Evaluates the model using MAE on the validation set.\n",
      "7. If the validation MAE is lower than $15,000, it predicts on the test set.\n",
      "8. Creates a submission file consistent with the competition's format.\n",
      "\n",
      "Please note that this is a starting point; the preprocessing and model selection might need to be refined to achieve the MAE goal you've described. Hyperparameter tuning, feature engineering, and possibly the use of more sophisticated models can further improve the MAE.\n",
      "\n",
      "\n",
      "--- LOGGING NEW ACTION ---\n",
      "Step: 25\n",
      "Calling function wrapped_complete_text_openai(args = (), kwargs = {'system_prompt': 'You are a helpful assistant. Please take the following code and return the content you would write into a python script file. Do not include the ```python or ``` at the beginning and end of the code.', 'user_prompt': 'It seems there was an attempt to read multiple files at once which caused an error. To solve the machine learning task, we want to write a Python script that reads the training data, preprocesses it, creates a model, performs training, validation, and finally, predicts sale prices for the houses in the test set. Here\\'s a sample code to get you started:\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Load training data\\ntrain_data = pd.read_csv(\\'train.csv\\')\\n\\n# Preprocessing\\n# Define features and target\\nX = train_data.drop([\\'SalePrice\\', \\'Id\\'], axis=1)\\ny = train_data[\\'SalePrice\\']\\nX = pd.get_dummies(X, dummy_na=True)  # Convert categorical data to one-hot encoding\\n\\n# Split training data into training and validation subsets\\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\\n\\n# Define and configure the model\\nmodel = make_pipeline(\\n    SimpleImputer(strategy=\\'median\\'),  # Impute missing values\\n    StandardScaler(),  # Scale features\\n    RandomForestRegressor(n_estimators=100, random_state=0)  # Random Forest model\\n)\\n\\n# Train the model\\nmodel.fit(X_train, y_train)\\n\\n# Predict on validation set\\ny_pred = model.predict(X_valid)\\n\\n# Evaluate the model\\nmae = mean_absolute_error(y_valid, y_pred)\\n\\nif mae < 15000:\\n    print(f\"Validation MAE: {mae:.2f}\")\\n\\n    # If validation MAE is below 15,000, proceed to predict on test set\\n    test_data = pd.read_csv(\\'test.csv\\')\\n    test_X = test_data.drop([\\'Id\\'], axis=1)\\n    test_X = pd.get_dummies(test_X, dummy_na=True)\\n    test_X = test_X.reindex(columns=X.columns, fill_value=0)  # Ensure the test data has the same columns as the training set\\n\\n    # Predict sale prices on test data\\n    test_preds = model.predict(test_X)\\n\\n    # Save the predictions to a CSV file\\n    output = pd.DataFrame({\\'Id\\': test_data.Id, \\'SalePrice\\': test_preds})\\n    output.to_csv(\\'submission.csv\\', index=False)\\n    print(\"Submission CSV is ready.\")\\nelse:\\n    print(f\"Validation MAE of {mae:.2f} did not meet the required threshold.\")\\n```\\n\\nThis script:\\n1. Loads the training data.\\n2. Preprocesses it, dealing with categorical variables through one-hot encoding.\\n3. Splits it into training and validation sets.\\n4. Defines a model pipeline that handles missing values, scales features, and trains a Random Forest.\\n5. Trains the model on the training set.\\n6. Evaluates the model using MAE on the validation set.\\n7. If the validation MAE is lower than $15,000, it predicts on the test set.\\n8. Creates a submission file consistent with the competition\\'s format.\\n\\nPlease note that this is a starting point; the preprocessing and model selection might need to be refined to achieve the MAE goal you\\'ve described. Hyperparameter tuning, feature engineering, and possibly the use of more sophisticated models can further improve the MAE.', 'max_tokens': 4096, 'temperature': 0.0, 'top_p': 0.0, 'work_dir': 'workspace\\\\home-data-for-ml-course_branch'})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = eureka_agent.initial_system_prompt(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 run this 32 times\n",
    "# 3 execute all 32\n",
    "# 4 take the best one and save its training history -- tbh not sure if there's a standardized way to do this? Perhaps have an agent extract just the MAE and just grab the best one. Mini waste of tokens, but it's very little. \n",
    "\n",
    "# Prompt 2: Reward reflection and feedback\n",
    "# 5 reward reflection and feedback\n",
    "# 6 run this 32 times\n",
    "# 7 execute all 32\n",
    "# 8 take the best one and save its training history\n",
    "# 9 repeat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
