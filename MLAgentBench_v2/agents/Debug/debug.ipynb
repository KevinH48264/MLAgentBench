{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory:  c:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\MLAgentBench\\MLAgentBench_v2\\agents\\Debug\\..\\..\\..\n",
      "New Working Directory: c:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\MLAgentBench\n"
     ]
    }
   ],
   "source": [
    "# This is a debug file from Eureka\n",
    "import os\n",
    "\n",
    "# Define the new working directory relative to the current working directory\n",
    "# or use an absolute path\n",
    "new_working_directory = os.path.join(os.getcwd(), '..', '..', '..') # Set to MLAgentBenhc\n",
    "print(\"New working directory: \", new_working_directory)\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_working_directory)\n",
    "print(\"New Working Directory:\", os.getcwd())\n",
    "\n",
    "from MLAgentBench_v2.agents.agent import Agent\n",
    "import numpy as np \n",
    "import json\n",
    "import logging \n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time \n",
    "import types\n",
    "import copy\n",
    "import ast\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'helm'\n",
      "Could not load CRFM API key crfm_api_key.txt.\n",
      "[Errno 2] No such file or directory: 'claude_api_key.txt'\n",
      "Could not load anthropic API key claude_api_key.txt.\n",
      "Initializing environment...\n",
      "args namespace(task='home-data-for-ml-course', task_type='kaggle', log_dir='logs/manual_debug', work_dir='workspace', max_steps=50, max_time=18000, device=0, python='/home/user/micromamba/envs/autogpt/bin/python', interactive=False, resume=None, resume_step=0, agent_type='DebugAgent', llm_name='gpt-4-1106-preview', fast_llm_name='gpt-4-1106-preview', edit_script_llm_name='gpt-4-1106-preview', edit_script_llm_max_tokens=4000, agent_max_steps=50, actions_remove_from_prompt=[], actions_add_to_prompt=[], no_retrieval=False, valid_format_entires=None, max_steps_in_context=3, max_observation_steps_in_context=3, max_retries=4, langchain_agent='zero-shot-react-description')\n",
      "Preparing task home-data-for-ml-course , of type:  kaggle\n",
      "\n",
      "\n",
      "--- RESTORING ENVIRONMENT CHECKPOINT HERE ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an environment\n",
    "from types import SimpleNamespace\n",
    "from MLAgentBench_v2.environment import Environment\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    task='home-data-for-ml-course',\n",
    "    task_type='kaggle',\n",
    "    log_dir='logs/manual_debug',\n",
    "    work_dir='workspace',\n",
    "    max_steps=50,\n",
    "    max_time=18000,\n",
    "    device=0,\n",
    "    python='/home/user/micromamba/envs/autogpt/bin/python',\n",
    "    interactive=False,\n",
    "    resume=None,\n",
    "    resume_step=0,\n",
    "    agent_type='DebugAgent', # Just for instantiation -- doesn't actually do anything\n",
    "    # llm_name='gpt-3.5-turbo-1106',\n",
    "    # fast_llm_name='gpt-3.5-turbo-1106',\n",
    "    # edit_script_llm_name='gpt-3.5-turbo-1106',\n",
    "    llm_name='gpt-4-1106-preview',\n",
    "    fast_llm_name='gpt-4-1106-preview',\n",
    "    edit_script_llm_name='gpt-4-1106-preview',\n",
    "    edit_script_llm_max_tokens=4000,\n",
    "    agent_max_steps=50,\n",
    "    actions_remove_from_prompt=[],\n",
    "    actions_add_to_prompt=[],\n",
    "    no_retrieval=False,\n",
    "    valid_format_entires=None,\n",
    "    max_steps_in_context=3,\n",
    "    max_observation_steps_in_context=3,\n",
    "    max_retries=4,\n",
    "    langchain_agent='zero-shot-react-description'\n",
    ")\n",
    "\n",
    "env = Environment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the agent\n",
    "class DebugAgent(Agent):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.env = env # allows you to interact with the environment using debug_agent.env\n",
    "\n",
    "debug_agent = DebugAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some subgoal\n",
    "research_problem = '''Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "Evaluation\n",
    "Goal\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. \n",
    "\n",
    "You want a train and validation MAE of lower than 11,000 and there should be a submission.csv containing predictions for test.csv ready to submit.\n",
    "\n",
    "Metric\n",
    "Submissions are evaluated on Mean-Absolute-Error (MAE) between the predicted value and the observed sales price.\n",
    "\n",
    "Submission File Format\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "Id,SalePrice\n",
    "1461,169000.1\n",
    "1462,187724.1233\n",
    "1463,175221\n",
    "etc.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- LOGGING NEW ACTION ---\n",
      "Step: 33\n",
      "Calling function wrapped_write_file(args = (), kwargs = {'file_name': 'train.py', 'content': '\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Assuming \\'train.csv\\' and \\'test.csv\\' are in the working directory, read them into a pandas dataframe\\ntrain_data = pd.read_csv(\\'train.csv\\')\\ntest_data = pd.read_csv(\\'test.csv\\')\\n\\n# Remove rows with missing target, separate target from predictors\\ntrain_data.dropna(axis=0, subset=[\\'SalePrice\\'], inplace=True)\\ny = train_data.SalePrice\\nX = train_data.drop([\\'SalePrice\\'], axis=1)\\n\\n# To keep things simple, we\\'ll use only numerical predictors\\nX = X.select_dtypes(exclude=[\\'object\\'])\\ntest_data = test_data.select_dtypes(exclude=[\\'object\\'])\\n\\n# Break off validation set from training data\\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\\n\\n# Simple imputation\\nfrom sklearn.impute import SimpleImputer\\nmy_imputer = SimpleImputer()\\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\\nimputed_X_test = pd.DataFrame(my_imputer.transform(test_data))\\n\\n# Imputation removed column names; put them back\\nimputed_X_train.columns = X_train.columns\\nimputed_X_valid.columns = X_valid.columns\\nimputed_X_test.columns = test_data.columns\\n\\n# Define model\\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\\n\\n# Fit model\\nmodel.fit(imputed_X_train, y_train)\\n\\n# Get validation predictions and MAE\\npreds_valid = model.predict(imputed_X_valid)\\nmae_valid = mean_absolute_error(y_valid, preds_valid)\\nprint(\"Validation MAE:\", mae_valid)\\n\\n# If the model is satisfactory, we can train on all the data and predict the test set\\nif mae_valid < 15000:\\n    model.fit(pd.DataFrame(my_imputer.fit_transform(X)), y)\\n    test_preds = model.predict(imputed_X_test)\\n    output = pd.DataFrame({\\'Id\\': test_data.Id, \\'SalePrice\\': test_preds})\\n    output.to_csv(\\'submission.csv\\', index=False)\\n', 'work_dir': 'workspace\\\\home-data-for-ml-course_branch'})\n",
      "\n",
      "--- TOOL SUCCESS ---\n",
      "\n",
      "\n",
      "--- Step: 34 not recorded in history\n",
      "\n",
      "--- Step Action: Calling function wrapped_write_file(args = (), kwargs = {'file_name': 'train.py', 'content': '\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Assuming \\'train.csv\\' and \\'test.csv\\' are in the working directory, read them into a pandas dataframe\\ntrain_data = pd.read_csv(\\'train.csv\\')\\ntest_data = pd.read_csv(\\'test.csv\\')\\n\\n# Remove rows with missing target, separate target from predictors\\ntrain_data.dropna(axis=0, subset=[\\'SalePrice\\'], inplace=True)\\ny = train_data.SalePrice\\nX = train_data.drop([\\'SalePrice\\'], axis=1)\\n\\n# To keep things simple, we\\'ll use only numerical predictors\\nX = X.select_dtypes(exclude=[\\'object\\'])\\ntest_data = test_data.select_dtypes(exclude=[\\'object\\'])\\n\\n# Break off validation set from training data\\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\\n\\n# Simple imputation\\nfrom sklearn.impute import SimpleImputer\\nmy_imputer = SimpleImputer()\\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\\nimputed_X_test = pd.DataFrame(my_imputer.transform(test_data))\\n\\n# Imputation removed column names; put them back\\nimputed_X_train.columns = X_train.columns\\nimputed_X_valid.columns = X_valid.columns\\nimputed_X_test.columns = test_data.columns\\n\\n# Define model\\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\\n\\n# Fit model\\nmodel.fit(imputed_X_train, y_train)\\n\\n# Get validation predictions and MAE\\npreds_valid = model.predict(imputed_X_valid)\\nmae_valid = mean_absolute_error(y_valid, preds_valid)\\nprint(\"Validation MAE:\", mae_valid)\\n\\n# If the model is satisfactory, we can train on all the data and predict the test set\\nif mae_valid < 15000:\\n    model.fit(pd.DataFrame(my_imputer.fit_transform(X)), y)\\n    test_preds = model.predict(imputed_X_test)\\n    output = pd.DataFrame({\\'Id\\': test_data.Id, \\'SalePrice\\': test_preds})\\n    output.to_csv(\\'submission.csv\\', index=False)\\n', 'work_dir': '.'})\n",
      "\n",
      "--- Step Result: File train.py written successfully.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File train.py written successfully.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the script manually\n",
    "\n",
    "# Grabbing code that I know executes\n",
    "\n",
    "python_code = '''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Assuming 'train.csv' and 'test.csv' are in the working directory, read them into a pandas dataframe\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice\n",
    "X = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "test_data = test_data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# Simple imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "imputed_X_test = pd.DataFrame(my_imputer.transform(test_data))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "imputed_X_test.columns = test_data.columns\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit model\n",
    "model.fit(imputed_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(imputed_X_valid)\n",
    "mae_valid = mean_absolute_error(y_valid, preds_valid)\n",
    "print(\"Validation MAE:\", mae_valid)\n",
    "\n",
    "# If the model is satisfactory, we can train on all the data and predict the test set\n",
    "if mae_valid < 15000:\n",
    "    model.fit(pd.DataFrame(my_imputer.fit_transform(X)), y)\n",
    "    test_preds = model.predict(imputed_X_test)\n",
    "    output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_preds})\n",
    "    output.to_csv('submission.csv', index=False)\n",
    "'''\n",
    "\n",
    "write_args = {\n",
    "    'file_name': f'train.py',\n",
    "    'content': python_code,\n",
    "    'update_files_action_result_history': False,\n",
    "}\n",
    "debug_agent.available_actions['writeFile'](**write_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- LOGGING NEW ACTION ---\n",
      "Step: 34\n",
      "Calling function wrapped_execute_script(args = (), kwargs = {'script_name': 'train.py', 'work_dir': 'workspace\\\\home-data-for-ml-course_branch'})\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script output: Validation MAE: 18250.608013698627\n",
      "\n",
      "\n",
      "\n",
      "--- LOGGING NEW ACTION ---\n",
      "Step: 34\n",
      "Calling function wrapped_complete_text_openai(args = (), kwargs = {'system_prompt': 'You are a helpful assistant. Your goal is to check if the code outputs the train and validation score, specifically not from log values, but normal values, and make sure that the code for calculating validation score is actually from a validation set. If so, then extract the train and validation score value from the result. If the code doesn\\'t output the train and validation score or its not for normal values or the code doesn\\'t actually calculate and print validation score from a validation set, then please write \"inf\" as the traing and validation score. Please also write down what type of validation score it is (ex. Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), accuracy, etc.)\\n            \\n            Example:\\n            ```json\\n            {\\n                \"observations\": \"<string>\",\\n                \"score_type\": \"<string>\",\\n                \"train_score\": <float>,\\n                \"val_score\": <float>\\n            }', 'json_required': True, 'user_prompt': 'Code: \\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Assuming \\'train.csv\\' and \\'test.csv\\' are in the working directory, read them into a pandas dataframe\\ntrain_data = pd.read_csv(\\'train.csv\\')\\ntest_data = pd.read_csv(\\'test.csv\\')\\n\\n# Remove rows with missing target, separate target from predictors\\ntrain_data.dropna(axis=0, subset=[\\'SalePrice\\'], inplace=True)\\ny = train_data.SalePrice\\nX = train_data.drop([\\'SalePrice\\'], axis=1)\\n\\n# To keep things simple, we\\'ll use only numerical predictors\\nX = X.select_dtypes(exclude=[\\'object\\'])\\ntest_data = test_data.select_dtypes(exclude=[\\'object\\'])\\n\\n# Break off validation set from training data\\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\\n\\n# Simple imputation\\nfrom sklearn.impute import SimpleImputer\\nmy_imputer = SimpleImputer()\\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\\nimputed_X_test = pd.DataFrame(my_imputer.transform(test_data))\\n\\n# Imputation removed column names; put them back\\nimputed_X_train.columns = X_train.columns\\nimputed_X_valid.columns = X_valid.columns\\nimputed_X_test.columns = test_data.columns\\n\\n# Define model\\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\\n\\n# Fit model\\nmodel.fit(imputed_X_train, y_train)\\n\\n# Get validation predictions and MAE\\npreds_valid = model.predict(imputed_X_valid)\\nmae_valid = mean_absolute_error(y_valid, preds_valid)\\nprint(\"Validation MAE:\", mae_valid)\\n\\n# If the model is satisfactory, we can train on all the data and predict the test set\\nif mae_valid < 15000:\\n    model.fit(pd.DataFrame(my_imputer.fit_transform(X)), y)\\n    test_preds = model.predict(imputed_X_test)\\n    output = pd.DataFrame({\\'Id\\': test_data.Id, \\'SalePrice\\': test_preds})\\n    output.to_csv(\\'submission.csv\\', index=False)\\n\\nResult after executing code: Validation MAE: 18250.608013698627\\n', 'max_tokens': 4096, 'temperature': 0.0, 'top_p': 0.0, 'work_dir': 'workspace\\\\home-data-for-ml-course_branch'})\n",
      "\n",
      "--- TOOL SUCCESS ---\n",
      "\n",
      "\n",
      "--- Step: 35 not recorded in history\n",
      "\n",
      "--- Step Action: Calling function wrapped_complete_text_openai(args = (), kwargs = {'system_prompt': 'You are a helpful assistant. Your goal is to check if the code outputs the train and validation score, specifically not from log values, but normal values, and make sure that the code for calculating validation score is actually from a validation set. If so, then extract the train and validation score value from the result. If the code doesn\\'t output the train and validation score or its not for normal values or the code doesn\\'t actually calculate and print validation score from a validation set, then please write \"inf\" as the traing and validation score. Please also write down what type of validation score it is (ex. Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), accuracy, etc.)\\n            \\n            Example:\\n            ```json\\n            {\\n                \"observations\": \"<string>\",\\n                \"score_type\": \"<string>\",\\n                \"train_score\": <float>,\\n                \"val_score\": <float>\\n            }', 'json_required': True, 'user_prompt': 'Code: \\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Assuming \\'train.csv\\' and \\'test.csv\\' are in the working directory, read them into a pandas dataframe\\ntrain_data = pd.read_csv(\\'train.csv\\')\\ntest_data = pd.read_csv(\\'test.csv\\')\\n\\n# Remove rows with missing target, separate target from predictors\\ntrain_data.dropna(axis=0, subset=[\\'SalePrice\\'], inplace=True)\\ny = train_data.SalePrice\\nX = train_data.drop([\\'SalePrice\\'], axis=1)\\n\\n# To keep things simple, we\\'ll use only numerical predictors\\nX = X.select_dtypes(exclude=[\\'object\\'])\\ntest_data = test_data.select_dtypes(exclude=[\\'object\\'])\\n\\n# Break off validation set from training data\\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\\n\\n# Simple imputation\\nfrom sklearn.impute import SimpleImputer\\nmy_imputer = SimpleImputer()\\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\\nimputed_X_test = pd.DataFrame(my_imputer.transform(test_data))\\n\\n# Imputation removed column names; put them back\\nimputed_X_train.columns = X_train.columns\\nimputed_X_valid.columns = X_valid.columns\\nimputed_X_test.columns = test_data.columns\\n\\n# Define model\\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\\n\\n# Fit model\\nmodel.fit(imputed_X_train, y_train)\\n\\n# Get validation predictions and MAE\\npreds_valid = model.predict(imputed_X_valid)\\nmae_valid = mean_absolute_error(y_valid, preds_valid)\\nprint(\"Validation MAE:\", mae_valid)\\n\\n# If the model is satisfactory, we can train on all the data and predict the test set\\nif mae_valid < 15000:\\n    model.fit(pd.DataFrame(my_imputer.fit_transform(X)), y)\\n    test_preds = model.predict(imputed_X_test)\\n    output = pd.DataFrame({\\'Id\\': test_data.Id, \\'SalePrice\\': test_preds})\\n    output.to_csv(\\'submission.csv\\', index=False)\\n\\nResult after executing code: Validation MAE: 18250.608013698627\\n', 'max_tokens': 4096, 'temperature': 0.0, 'top_p': 0.0, 'work_dir': '.'})\n",
      "\n",
      "--- Step Result: \n",
      "{\n",
      "    \"observations\": \"The code outputs the validation score as the Mean Absolute Error (MAE) from the validation set after predicting with a RandomForestRegressor. The training score is not directly outputted by the code.\",\n",
      "    \"score_type\": \"Mean Absolute Error (MAE)\",\n",
      "    \"train_score\": \"inf\",\n",
      "    \"val_score\": 18250.608013698627\n",
      "}\n",
      "\n",
      "--- TOOL SUCCESS ---\n",
      "\n",
      "\n",
      "--- Step: 36 not recorded in history\n",
      "\n",
      "--- Step Action: Calling function wrapped_execute_script(args = (), kwargs = {'script_name': 'train.py', 'work_dir': '.'})\n",
      "\n",
      "--- Step Result: Script output: Validation MAE: 18250.608013698627\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the script\n",
    "execute_args = {\n",
    "    'script_name': 'train.py',\n",
    "    'update_files_action_result_history': False,\n",
    "}\n",
    "result = debug_agent.env.execute_script(**execute_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
