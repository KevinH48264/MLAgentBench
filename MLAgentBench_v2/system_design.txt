Goal: Creating an E2E system for testing as many agent frameworks and prompts (Eureka, Voyager, OPRO) as fast as possible.

Inputs:
1. Research Problem: Ex. "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable."
2. Environment
Process: Agent system
Output: Research Problem output (submission.csv)

Principles:
1. Curriculum agent system interface
- answer state (s) = #_relevant_steps * ({attempted task, plan, result, files, answer_state})
- action space (A) = proposing a next task
- reward model (R(s)) = research_problem
- policy (pi) = LLM
- transition model (P(s'|s,a)) = results from tactical agent executing in the reality
2. Tactical agent system interface
- memory state (s) = #_history * ({action, result, files}) -- only actions from methods, executor, critic agent?
- action space (A) = actions & tools (reflection, read file, etc.)
- reward model (R(s)) = task
- policy (pi) == LLM
- transition model (P(s'|s,a)) = executing in reality
3. Environment class -- keep lightweight
- Files -- work dir (includes a skill library of tasks and successful plans)
- Action functions -- Code Interpreter, Read File, Write File, Search, Reflect, Final Answer
- Log files -- log dir, supports logging of action functions
4. Experimenting with different parameters via scripting

MLAgentBench/
├── environment.py          # Minimal environment wrapper
    ├── research_problem.txt    # Research problem
    └── actions.py              # Minimal actions
├── agents/agent.py         # All agent classes defined here with a simple base class
├── prepare_task.py         # Prepare workspace
└── runner.py               # Script to run an experiment with dynamic agent loading
workspace/                  # Folder of files
│
├── <task-name>/            # Original downloaded or custom uploaded starter files
    └── skill_library/      # Global folder of successful tasks and their plans
└── <task-name>-branch/     # Branch that is the workspace of the agent
    └── skill_library/      # Copy of global skills library
logs/                       # Logs where of main log, workspace saves, and env saves

E2E Flow:
0. Environment already has Actions pre-defined by owner.
- List files (environment for actions, )
- Read file
- Write file (only in workspace)
- Search
- Think
- Final answer
- An OpenAI Assistant class will also be provided to take in a prompt and give an output after running through all the Actions it decides is necessary.  (can be turned on or off)
- You.com Agent
- Note: Logging is automatically invoked whenever an Action is invoked, saving state of work_dir in log_dir
1. User wants to solve the house-price task from Kaggle. They enter a command for this.
2. We prepare the house-price 1. Research Problem and 2. Workspace in work_dir. We automatically run prepare.py to prepare the environment.
3. Then the user can choose an existing agent class or write a new agent class that takes in the environment and writes an agent to try succeeding in the environment given the research goal.
4. The output of that agent class should be giving proof that it fulfilled the research goal and that I will check.

Concerns:
1. Does it handle Eureka, Voyager, and OPRO changes easily?
Eureka -- need to be able to give environment.py and research_problem, which is good. Only problem is that environment.py might be too long. Therefore, we'll modularize it so that most of the utils are elsewhere. There can be a repetition step that keeps going for like 50 rounds and tries to improve itself too, and only returns the best answer at the end. This would work.

Voyager -- I'll have to write the other agents, but most of the code should be doable and really just relies on a workspace accessible and keeping information in a file or variable. And then it'll return. 

OPRO -- This is a meta prompter which can effectively give another agent instructions to build Eureka or Voyager. Running this with the right prompt and code should be doable. I can establish how many times to improve, and give the starter code to motivate OPRO to prompt and improve prompts. This will look like Eureka.